\documentclass[a4paper]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{natbib}
\usepackage{hyperref} % links
\usepackage{multirow} % context example table
\usepackage{array} % fixed-width columns with left alignment
\usepackage{graphicx} % include the map
\usepackage[outline]{contour} % contour place names in the cosine similarity figure
\usepackage[dvipsnames]{xcolor} % colour-code the groups (has to come before tikz)
\usepackage[geometry]{ifsym} % shape-code the groups
\usepackage[section]{placeins} % don't let the graphics/tables move past sections
\usepackage{float} % place figures where I want them
\usepackage{pdfpages} % add non-plagiarism statement (has to be after xcolor)
\usepackage{tipa} % IPA
\usepackage{amsmath} % formulae
\usepackage{dsfont} % real numbers symbol
\usepackage{mathtools} % display style in formulae with branching cases
\usepackage{forest} % (non-dendrogram) trees
\usetikzlibrary{decorations.pathreplacing} % draw braces in tikz figures
\usepackage{standalone} % import figures
\usepackage{changepage} % adjust text width
\usepackage{parskip} % proper paragraphs, no indentation

% For the map keys.
\definecolor{purple}{HTML}{520066}
\definecolor{midblue}{HTML}{31688e}
\definecolor{green}{HTML}{35b779}
\def\upper{\color{purple}\FilledBigTriangleUp}
\def\central{\color{midblue}\FilledBigSquare}
\def\dutch{\color{green}\FilledBigCircle}
\def\ingv{\color{green}\BigCircle}

% For specifying matrix dimensions. (set of real numbers symbol)
\newcommand{\R}{\mathds{R}}

\title{Clustering Dialect Varieties Based on Historical Sound Correspondences}
\author{Verena Blaschke}
\date{\today}

\begin{document}

\begin{titlepage}
\begin{center}

\vspace*{.15\textheight}

{\Large Bachelor's Thesis}
\vspace{2em}

\hrule
\vspace{0.6cm}
{\bfseries\huge
Clustering Dialect Varieties

Based on

\vspace{4mm}
Historical Sound Correspondences
}\\[0.7cm] 
\hrule
\vspace*{.05\textheight}
 
\begin{minipage}[t]{0.49\textwidth}
\begin{flushleft} 
{\large
\textit{Author}\\
Verena Blaschke}\\
\href{mailto:verena.blaschke@student.uni-tuebingen.de}{\textit{verena.blaschke@student.\\uni-tuebingen.de}}\\
\end{flushleft}
\end{minipage}
\begin{minipage}[t]{0.49\textwidth}
\begin{flushright}
{\large
\textit{Supervisor}\\
Dr. Çağrı Çöltekin}\\
\href{mailto:ccoltekin@sfs.uni-tuebingen.de}{\textit{ccoltekin@sfs.uni-tuebingen.de}}\\
\end{flushright}
\end{minipage}\\

\vfill

A thesis submitted in partial fulfillment\\
of the requirements for the degree of\\[2mm]
{\large Bachelor of Arts}\\
in\\[1mm]
{\large International Studies in Computational Linguistics}

\vspace*{.1\textheight}

{\large Seminar für Sprachwissenschaft\\
Eberhard Karls Universität Tübingen

\vspace{1em}
August 2018}
\end{center}
\end{titlepage}

\pagenumbering{gobble}

\newpage
% \includepdf[pages=-]{antiplagiatserklaerung_blank}
\includepdf[pages=-]{antiplagiatserklaerung_scan}

\newpage
\section*{Abstract}
While information on historical sound shifts
plays an important role for examining
the relationships between related language varieties,
it has rarely been used for computational dialectology.
This thesis explores the performance of two algorithms
for clustering language varieties
based on sound correspondences between Proto-Germanic
and modern continental West Germanic dialects.
Our experiments suggest that the results of agglomerative clustering
match common dialect groupings more closely
than the results of (divisive) bipartite spectral graph co-clustering.
We also observe that adding phonetic context information
to the sound correspondences yields clusters
that are more frequently associated with representative and distinctive
sound correspondences.

\newpage
\tableofcontents
\newpage
\listoftables
\listoffigures
\newpage

\pagenumbering{arabic}

\section{Introduction}

Language variation and change have long been a focus of linguistics.
The\linebreak analyses necessary for determining
systematic similarities and differences between language varieties
had to originally be exclusively performed by hand,
but with the advances of computational methods,
it has become possible to carry out quantitative analyses more easily.
One field concerned with such analyses is \textit{dialectometry},
which focuses on computational and statistical methods for dialectology.

Applying quantitative methods to dialectology gives the advantage
that statistical models can work using all the feature
information of the data that they are given,
quickly evaluating for each feature how well it does or does not
describe similarities or differences in the data.

In this thesis, we examine a set of West Germanic language varieties
currently spoken in continental Europe.
We compare them by investigating how they have changed phonologically
since a shared ancestral stage of Germanic from around 2500 years ago.
Our goal is to automatically assign a cluster structure to the
modern language varieties that reflects shared sound changes
within each cluster and differences between sound shifts between different clusters.

This thesis is structured as follows:
In the following subsection, we present the
dialectometrical approaches that influenced our work.
Then we begin by introducing the data in section~\ref{sec:data}.
Next, in section~\ref{sec:cwg},
we give a brief introduction to continental West Germanic languages and dialects,
as well as proposed ways of sorting them into groups
and the problems associated with doing this.
In section~\ref{sec:methods}, we explain our methodology for
aligning the data and extracting sound correspondences,
describe two approaches to clustering the data,
and then explain how we rank the sound correspondences
associated with each cluster.
We present the results in section~\ref{sec:results}
and discuss them in section~\ref{sec:discussion},
before concluding the thesis in section~\ref{sec:conclusion}.

\subsection{Related Work}

In the past decades, there have been many advances in the field of dialectometry.%
\footnote{%
For thorough overviews, see \citet{nerbonne2009data} and \citet{wieling2015advances}.
}
The following works are especially relevant in the context of this thesis.

\citet{prokic2012detecting} perform hierarchical clustering
on Bulgarian dialects based on phonetic distances.
% One of our clustering approaches is similar to this,
% although we use different methods measuring the distance between a pair of dialects
% and for transforming the distance values into a hierarchical structure.
This is %also
similar to the work by \citet{prokic2007identifying},
wherein she performs an aggregate analysis of the
data via an unspecified clustering method based on a
dialect-by-dialect matrix storing phonetic distance values,
which she compares to individual analyses of recurring sound correspondences
between the dialects.
The latter analyses are in turn related to the work by
\citet{prokic2013combining} who explore more closely how
to automatically judge the regularity of sound correspondences
for investigating dialect transitions in the geographical spread.

\citet{heggarty2010splits} worked with modern varieties of Germanic languages.
They applied the NeighborNet method \citep{bryant2004neighbornet}
based on pronunciation differences to represent the data as a
web-like phylogenetic network.

\citet{proell2013detecting} also investigated a clustering method
that does not use strict hierarchies or categories by
applying fuzzy clustering on the basis of lexical variation
to capture gradual changes between dialect groups.

\citeauthor{wieling2011bipartite} (\citeyear{wieling2009bipartite}; \citeyear{wieling2011bipartite})
examined the relation between dialect groups and
the phonetic properties that categorize them.
They extracted sound correspondences between dialects
and a reference dialect
and used bipartite spectral graph co-clustering
for simultaneously clustering sound correspondences and dialects.
This method was originally introduced for data mining
\citep{dhillon2001co-clustering, zha2001bipartite},
but it has also been used in bioinformatics \citep{kluger2003spectral}.
\citeauthor{wieling2011bipartite}
(\citeyear{wieling2009bipartite}; \citeyear{wieling2011bipartite})
applied this method to dialects spoken in the Netherlands.

A hierarchical version of this co-clustering method
was used by \citet{wieling2010hierarchical},
again for dialects spoken in the Netherlands,
and \citet{wieling2013analyzing} employed this method for
clustering British English dialects.
\citet{montemagni2013synchronic} applied this method to Tuscan dialects,
and supplemented the sound correspondences with information
on the phonetic contexts of the sound segments in the correspondences.

Our usage of phonetic context information is also
influenced by the work of \citet{wettig2012using}
who used context-sensitive sound correspondence rules
for aligning phonetically transcribed data from related languages.

\section{Data}
\label{sec:data}

We work with phonetically transcribed data from
continental European West Germanic (henceforth: CWG)
dialects and standard languages
(hereafter collectively referred to as doculects).
The data we work with are taken from the Sound Comparisons project,
an extension of the Languages and Origins in Europe project \citep{renfrew2009languages},
lead by \citet{heggarty2018sound},
who compiled IPA transcriptions of word lists
in a range of Germanic doculects.

From this database,
we used 110 cognate sets (also referred to as \textit{concepts})
from 20 modern CWG doculects
and a reconstructed version of Proto-Germanic.%
\footnote{%
The Sound Comparisons project does not state
the theoretical basis for the Proto-Germanic reconstruction.
According to the project website,
the reconstruction might be close to
a variant of the language spoken in around 500 BCE
in Southern Scandinavia.
}
Of the modern doculects, two are identified as standard languages
in the database (Dutch spoken in the Netherlands and Belgium%
\footnote{%
Hereafter referred to as \textit{Std. Dutch (NL)}
and \textit{Std. Dutch (BE)}, respectively.
}),
the rest as local vernaculars.
The modern doculects are from locations in the
Netherlands, Belgium, Luxembourg, (along the Western border of) Germany,
France (Alsace), Switzerland, Liechtenstein, Austria (Voralberg), and Italy (South Tyrol).
Figure~\ref{fig:map} provides an overview of these locations.
The legend is explained in section~\ref{sec:cwg}.

For the phonetic alignment step (see section~\ref{subsec:msa}),
we used 14 additional doculects that are Germanic but not CWG. 
To control for transciber bias,
i.e. different transcribers providing
slightly different transcriptions of identical sounds,
we only worked with doculects that share the same transcriptor,
Warren Maguire.
The transcriptions of the modern doculect data
are narrow transcriptions;
that of the Proto-Germanic reconstruction appears to be broader.%
\footnote{%
For instance, the Proto-Germanic data include no suprasegmentals.
}

The concepts are often represented in root forms
of the words to mitigate the overrepresentation
of certain affixes \citep{renfrew2009languages}.%
\footnote{%
E.g., verbs are represented in their imperative forms
rather than the infinitive.
}

We excluded one CWG doculect that covered only 35 concepts. % Schaeddel (Frisian)
The Proto-Germanic data cover all 110 concepts; each of the modern doculects covers at least 103 concepts, and each concept is covered by at least 17 modern doculects.
In total, we have 2181 word alignments between Proto-Germanic and modern CWG doculects.


\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{figures/map.pdf}
\caption
[Locations of the modern continental West Germanic doculects]
{Locations of the modern continental West Germanic doculects we worked with.}
\label{fig:map}
\end{figure}


% \newpage
\section{Continental West Germanic}
\label{sec:cwg}

The CWG doculects include several standard languages
(standard varieties of Dutch spoken in Belgium and the Netherlands,
Luxembourgish, standard varieties of German in
Germany, Austria, Switzerland and Liechtenstein)
as well as many regiolects and dialects.
Establishing subgroups within this collection of doculects provides a challenge
that has been taken up many times, with different results.
Even the classification of West Germanic
as its own branch of Germanic is controversial,
though generally accepted
(\citet{voyles1971problem}; \citet[pp. 7-8]{harbert2007germanic}; \citet{ringe2012cladistic}).

Within the CWG group, it gets even more complicated and contested.
\citet[pp. 72-80]{nielsen1989germanic} gives an overview of the history of attempts to divide the West Germanic dialects into subgroups with the associated criteria (phonological, morphological, lexical, and/or extra-linguistic) and criticisms.

Much of the challenge of grouping CWG doculects stems from
them being very similar to one another and closely related.
These similarities do not only exist because of genetic relatedness
but also\textemdash{}enabled by the geographic proximity\textemdash{}mutual influences
\citep[p. 8]{harbert2007germanic}.

On the other hand, 
interactions between dialects and standard languages
have also influenced the dialect landscape
\citep{coetsem1992interaction}.
\citet{kremer1990einfuehrung} found that in Germany and in the Netherlands
(but not in Switzerland), dialects tend to become closer to the standard languages,
with the result of state or standard language borders tending to act as dialect borders.%
\footnote{%
They also found that Low German dialects and CWG spoken in
Non-Germanic regions tend to be replaced by the prevailing standard language instead.}

\citet{heggarty2010splits} describe models for intra-family variation,
most importantly two major models:
the tree-like, hierarchical \textit{splits} model,
and the \textit{waves} model, which corresponds more closely to a dialect continuum.

A combination of the two is reflected in Figure~\ref{fig:cwg_harbert},
which shows a proposed division of CWG doculects
into three main groups: North Sea Germanic (including Frisian and Low German),
Franconian (including Dutch and High Franconian)
and Alpine Germanic (including Alemannic and Bavarian),
and presents High German as the result of the convergence
of High Franconian, Alemannic and Bavarian.

\begin{figure}[H]
\centering
\includestandalone[width=\textwidth]{figures/harbert}
\caption
[The internal structure of continental West Germanic
based on \citet{harbert2007germanic}]
{The internal structure of continental West Germanic
based on \citet[p. 8]{harbert2007germanic}.}
\label{fig:cwg_harbert}
\end{figure}

\citet{heggarty2010splits}, who have inspected the same data
that we work with, describe their results as
``a progressive dialect continuum [...] incrementally proceeding in fairly close step
with geography.''

Alternatively, \citet{hammarstroem2018glottolog},
whose language catalogue Glottolog contains strictly hierarchical categorizations,
give an entirely tree-like classification of the CWG doculects,
as shown in Figure~\ref{fig:glottolog}.
This classification is based on the work by \citet{stiles2013pan-west}
and, like the previous figure, \citet{harbert2007germanic}.
We include it here since the output of our clustering methods
is also strictly hierarchical.
\vspace{-0.6em}
\begin{figure}[H]
\begin{adjustwidth}{-10cm}{-10cm}
\centering
\scalebox{0.8}{
\input{figures/glottolog}
}
\end{adjustwidth}
% \includestandalone[width=\textwidth]{figures/glottolog}
\caption
[
The full classification tree for the modern doculects we used,
as defined by \citet{hammarstroem2018glottolog}
]
{
The full classification tree (up to West Germanic) for the modern doculects we used
as defined by \citet{hammarstroem2018glottolog}.
The names of the modern doculects are dispayed in italics.
}
\label{fig:glottolog}
\end{figure}

\subsection{North Sea Germanic}

\citet{stiles2013pan-west} posits that
the most significant division of West Germanic varieties is
the split into Ingv\ae{}onic (that is, North Sea Germanic) varieties
and non-Ingv\ae{}onic varieties.
This split is also supported by, e.g., \citet[p. 7]{harbert2007germanic}, \citet[pp. 117--123]{sonderegger1979grundzuege} and \cite{auwera2017germanic}.
What is more complicated is defining which doculects are Ingv\ae{}onic:
\begin{itemize}
\item 
\citet{stiles2013pan-west} defines this group
as Frisian, English, and ``to a certain extend, Old Saxon'' (i.e., Low German).

\item
\citet[pp. 7--8, 17]{harbert2007germanic} defines it
as Frisian, English, and Low German,
while noting that Dutch has also been influenced by the Ingv\ae{}onic languages.

\item
% \todo{elaborate on 'more recently'}
\citet[pp. 71, 117--123]{sonderegger1979grundzuege} classifies Ingv\ae{}onic
as Frisian, English, Low German and (having become a part of this group more recently) Dutch.

\item
\Citet{auwera2017germanic} define Ingv\ae{}onic as Frisian, English, and Dutch.
\end{itemize}

The distinct properties of the Ingv\ae{}onic subgroup
concern mostly inflection and pronouns
(\citet{stiles2013pan-west}; \citet[pp. 7-8]{harbert2007germanic}),
although \citet{stiles2013pan-west} also lists some phonological characteristics:
``backing of long and short *\textit{a} before nasals [...];
fronting of long and short *\textit{a};
and palatalization of velar consonants''.

We follow the categorization by \citet{harbert2007germanic}, 
as it reconciles most of the aforementioned classification options.
A split similar to the one proposed by \citet{sonderegger1979grundzuege}
is part of the following section.
We thus divide the modern doculects from our dataset as follows:

\begin{itemize}
\item 
\textbf{Ingv\ae{}onic:}
Feer, Heligoland, Grou,
Westerkwartier, Veenkoloni\"{e}n, Achterhoek

\item
\textbf{Non-Ingv\ae{}onic:}
Std. Dutch (NL), Std. Dutch (BE), Ostend, Antwerp, Limburg,
Herrlisheim, Luxembourg, Cologne,
Ortisei, T\"{u}bingen, Walser, Biel, Hard, Graub\"{u}nden.
\end{itemize}

In Figure~\ref{fig:map}, the Ingv\ae{}onic doculects
are marked with green-rimmed, non-solid circles.

\subsection{Results of the High German Sound Shift}

A very important development for some of the CWG doculects,
especially High German, is the High German sound shift.%
\footnote{%
The term \textit{High German sound shift} has been used both
to describe the High German consonant shift,
and to describe the consonant shift as well as
sound shifts concerning the High German vowel system.
We use it here with the former meaning.
}
Summarizing \citet[pp. 47--48]{harbert2007germanic}
and \citet[pp. 62--64]{koenig2015dtv},
we can outline the High German sound shift as follows:

The voiceless (aspirated)%
\footnote{%
Aspiration is not marked in the reconstructed version of Proto-Germanic
we worked with.
}
Germanic stops (/*p, *t, *k/)
underwent lenition and shifted into affricates or fricatives.
(Typically, these stops developed into fricatives in postvocal positions,
and into affricates in word-inital or postconsonantal positions.
Moreover, /*t/ changed more commonly than /*p/,
which in turn changed more commonly than /*k/.)
To balance this out,
the voiced Germanic stops (/*b, *d, *g/) on the other hand
developed into their voiceless (and aspirated) counterparts.

Generally, these changes are more pronounced
in the Southern CWG area, and did not take place in the North
\cite[p. 33]{noble1983modern}%
\footnote{%
It is therefore generally assumed that the locations
from which these changes spread are in the Southern CWG area,
although there are also some controversies surrounding this
\citep[pp. 155--181]{goblirsch2005lautverschiebungen}.
}.
In between, there are many doculects
that only partially realized the High German sound shift,
with some of the changes only applying to individual words
\citep[p. 63]{koenig2015dtv}.

Based on this, there is a common division
of CWG doculects spoken in Germany into three groups:
Upper German doculects, which almost completely
exhibit lenition for all three voiceless stops
(except for sometimes /*k/ $>$ /(k)x/),
Central German doculects, which show a
partial development of the High German sound shift,
and Low German doculects,
which were not influenced by the High German sound shift
\citep[pp. 33, 55]{noble1983modern}.

This division is performed based on
the presence or absence of this shift in individual words \citep[p. 63]{koenig2015dtv}.
The pronunciation boundaries (\textit{isoglosses}) for such words
sometimes appear tightly bundled together,
although such bundles can also fan out such that a region
contains a continuum of very subtle dialect differences,
as is the case for the so-called Rhenish Fan at the Western part
of the boundary (or transition zone) between Low and Central German
\citep[pp. 63, 138, 141]{koenig2015dtv}.

We base the following classification of
the CWG doculects we worked with
on maps by \citet[pp. 64, 230--231]{koenig2015dtv}:%
\footnote{%
Central German is delimited % TODO word choice
to the North (Low German) with an isogloss bundle
containing words exhibiting
the absence (Low German) or presence (Central German)
of affrication or spirantization for
/p/ (e.g. \textit{schlapen}/\textit{schlafen} `sleep'),
/t/ (e.g. \textit{Tid}/\textit{Zeit} `time',\linebreak
\textit{Water}/\textit{Wasser} `water') and
/k/ (e.g. \textit{maken}/\textit{machen} `make').
The isogloss bundle serving as boundary between
Central and Upper German focuses on the
affrication of /p/ in Upper German
(e.g. \textit{Appel}/\textit{Apfel} `apple').
}

\begin{itemize}
\item
\textbf{Low German, Dutch, and Frisian:}
Westerkwartier, Veenkoloni\"{e}n, Achterhoek,
Feer, Heligoland, Grou,
Std. Dutch (NL), Std. Dutch (BE), Ostend, Antwerp and Limburg.

\item
\textbf{Central German:}
Cologne and Luxembourg.

\item
\textbf{Upper German:}
T\"{u}bingen, Herrlisheim,
Biel, Graub\"{u}nden, Walser, Hard and Ortisei.
\end{itemize}

Figure~\ref{fig:map} shows this division:
Low German, Dutch and Frisian are marked with circles,
Central German with blue squares and Upper German with purple triangles.

This division also matches the intra-database grouping by \citet{heggarty2018sound}
(who additionally split up the first group into
Low German on the one hand,
and Frisian, Dutch and Flemish on the other).

% \newpage
\section{Methods}
\label{sec:methods}

In section~\ref{subsec:msa}, we describe how we align
the phonetic transcriptions from our data.
From the aligned data, we extract sound correspondences
(section~\ref{subsec:corres}), which we then use for
two different clustering methods (section~\ref{subsec:clustering}).

We implemented these methods in Python
making use of several libraries for statistical analyses:
NumPy \citep{oliphant2006guide}, SciPy \citep{jones2001scipy},
scikit-learn \citep{pedregosa2011scikit-learn} and LingPy \citep{list2018lingpy}.

\subsection{Multiple Sequence Alignment}
\label{subsec:msa}

We carry out alignment based on data from
all the investigated doculects at once using multiple sequence alignment.
Doing this instead of performing pairwise alignment between
the Proto-Germanic and the modern data makes it possible\textemdash{}in addition to using patterns found in doculect-specific
sound correspondences\textemdash{}to base the alignment on commonalities
between the modern doculects.
Because of this, we use all of the modern Germanic data
we extracted from the Sound Comparisons project
instead of only the CWG doculects.

We use a library-based version \citep{notredame2000t-coffee:} of the progressive multiple sequence alignment method \citep{thompson1994clustal}.
For each concept:

\begin{enumerate}
\item
We divide the phonetic representation of each word into an array of sound segments.
These sound segments are typically single IPA tokens (plus diacritics),
but we use multi-token segments for affricates, diph- and triphthongs and geminates.%
\footnote{%
Allowing multi-token segments differs from
the method employed by, e.g., \citet{wieling2010hierarchical}.
They neither allowed multi-token segments nor did they add contextual information
(see section~\ref{subsec:corres}),
but they remark on a common alignment $\emptyset$:[\textesh],
which frequently appears after [t]:[t].
We opt instead to interpret affricates as single segments with
the result of correspondences such as [t]:[\texttoptiebar{t\textesh}].
}

\item
We then generate alignments for all possible pairwise combinations
of (modern or historical) doculects.
These alignments are created using the algorithm by \citet{needleman1970general},
with a scoring scheme based on the sound classes introduced by \citet{list2012sca}.%
\footnote{%
The sound classes are elaborated upon in section~\ref{subsec:corres}.
}
All segment alignments from this step are stored in a so-called \textit{library},
each associated with a weight reflecting its relative frequency.
% TODO. in how far does it reflect probable sound class changes in the LingPy implementation (vs. relative frequency)

\item
We create a sequence-by-sequence distance matrix
from the similarity information between each pair of aligned sequences
that was used by the scoring scheme in the previous step.
We convert the distance matrix into a tree using the UPGMA method \citep{sokal1958statistical}.%
\footnote{This method is explained in section~\ref{subsubsec:upgma}.}

\item 
Progressing from the tips of the tree to the root,
we consecutively join the alignments meeting at branchings
based on the library created in the first step,
until (at the root) all alignments have been consolidated into one alignment table.
\end{enumerate}

We use the LingPy library for Python \citep{list2018lingpy} to perform these steps.
Table~\ref{tab:msa}
shows an excerpt from the multiple sequence alignment for the concept ``cold''.

\begin{table}[h]
\begin{center}
\input{tables/msa}
\end{center}
\caption
[An excerpt from the aligned sequence table for the concept ``cold'']
{An excerpt from the aligned sequence table for the concept ``cold''.}
\label{tab:msa}
\end{table}

\subsection{Sound Correspondence Extraction}
\label{subsec:corres}

After performing sound segment-wise alignment,
we extract sound correspondences between
Proto-Germanic and each modern doculect from the alignment tables for all concepts.
We use straightforward segment-to-segment correspondences
as well as correspondences that include contextual information:

\begin{itemize}
\item
\textbf{No context}:
These are simple segment-to-segment correspondences.

\item
\textbf{Simple context}:
We (separately) add information about the
left and right single-segment context,
stating whether the context is a consonant or a vowel. 
This can only be performed when the context in question is of
the same type for both Proto-Germanic and the modern doculect.

\item
\textbf{Sound class-based context}:
This is similar to the previous category,
but we give more fine-grained information about consonants and vowels.
We use the sound classes introduced by \citet{list2012sca},
which discern between fifteen consonant groups and six vowel groups.

\item
\textbf{Word boundaries}:
When the (left or right) context is a word boundary,
we add information about this.

\end{itemize}

Table~\ref{tab:context} provides an overview
of the different context types,
with the corresponding IPA characters found in our data
in the case of \citeauthor{list2012sca}'s sound classes.
IPA characters with diacritics are classified
like their diacritic-less counterparts,
and diphthongs and triphthongs are classified
according to the first character in the sequence.
Table~\ref{tab:corres} shows the sound correspondences
that can be inferred for the aligned segments
from Proto-Germanic and Ortisei German for the alignment
shown in Table~\ref{tab:msa}.

\begin{table}[t]
\input{tables/context}
\caption
[Context representations by context type]
{Context representations by context type.
For the sound class-based context information
\citep{list2012sca}, the corresponding IPA characters
appearing in our data are included.}
\label{tab:context}
\end{table}

\begin{table}[b!]
\input{tables/corres}
\caption
[Proto-Germanic--Ortisei German sound correspondences
extracted from the aligned entries for the concept ``cold'']
{Proto-Germanic--Ortisei German sound correspondences
extracted from the aligned entries for the concept ``cold''.}
\label{tab:corres}
\end{table}

\FloatBarrier

The context information we use is different from the approach
by \citet{montemagni2013synchronic} in that they only
distinguished between consonants, vowels, glides, gaps and word boundaries.
Moreover, they included left and right context information simultaneously.
They also added context information when it is different for
the reference doculect and the doculect used for clustering,
whereas we present context information in a style more similar to 
the phonological rewrite rules introduced by \citet{chomsky1968sound}.

We ignore gap-gap alignments,
as they do not contain information on correspondences
between Proto-Germanic and the modern doculect in question,
only about inserted sound segments in one or more other doculects.
Furthermore, we treat insertions and deletions
that LingPy flags as swaps (metathesis) as normal insertions or deletions,
as such cases only happen for 3 of the 110 concepts.

For each doculect, we ignore sound correspondences
that occur fewer than three times across all concepts
to reduce the effect misalignments might have. 

After extracting the sound correspondences for
all modern doculects, we have a doculect-by-correspondence
matrix storing the absolute frequencies of the sound correspondences.

\subsection{Clustering}
\label{subsec:clustering}

We implemented two approaches to custering the data.
Both clustering approaches follow a similar structure:
we first normalize the doculect-by-correspon-dence tally matrix
to adjust feature frequencies by how informative they are,
then we perform hierarchical clustering.
Each approach is carried out once with only
the context-less sound correspondences
and once with all context types.

\subsubsection{Agglomerative Clustering}
\label{subsubsec:upgma}

This approach is similar to
a method used by \citet{prokic2012detecting}
in that it involves agglomerative clustering.
However, we use different procedures for measuring
distances between pairs of doculects and
for transforming the distance values into a hierarchical structure.

We first transform the frequencies
in the doculect-by-correspondence tally matrix
by applying TF-IDF weighting.

Term frequency (TF) measures the relative frequency
of each sound correspondence within a doculect \citep{luhn1957statistical}:

\begin{adjustwidth}{-1cm}{-1cm}
\begin{equation*}
\operatorname{tf}(doculect_i, corres_j) =
\frac{\text{number of occurrences of } corres_j \text{ in } doculect_i}
{\text{number of occurrences of all sound correspondences in } doculect_i}
\end{equation*}
\end{adjustwidth}

while inverse document frequency (IDF)
considers how many doculects cover a given
sound correspondence \citep{spaerck1972statistical}:

\begin{equation*}
\operatorname{idf}(corres_j) =
log(
\frac{\text{number of doculects}}
{\text{number of doculects with } corres_j}
).
\end{equation*}

To combine term frequency and inverse document frequency
and transform the tally matrix, 
we use the implementation from the Python library scikit-learn
\citep{pedregosa2011scikit-learn},
where TF-IDF is calculated as

\begin{equation*}
\operatorname{tf-idf}(doculect_i, corres_j) =
\text{tf}(doculect_i, corres_j)
\times
(
\text{idf}(corres_j)
+ 1).
\end{equation*}

We create a doculect-by-doculect distance matrix
with distances bounded between $0$ (identical) and $1$ (maximally different)
by calculating the cosine distances between each
binary combination of row vectors from the doculect-by-correspondence matrix
(where $doculect_i$ and $doculect_j$ refer to the $i$th and $j$th row vectors, respectively):

\begin{equation*}
\operatorname{cosine\_distance}(doculect_i,doculect_j) =
1 -
\frac{doculect_i \cdot doculect_j}{\lVert doculect_i \rVert \lVert doculect_j \rVert}
.
\end{equation*}

We then convert this distance matrix into a dendrogram using the
Unweighted Pair Group Method using Arithmetic Averages
(UPGMA) method introduced by \citet{sokal1958statistical}:

\begin{enumerate}
\item
Each doculect forms a singleton cluster.

\item
The two most similar clusters are merged into a new cluster.
The distance between this new cluster $B$ and any given cluster $C$ is
\begin{equation*}
\operatorname{dist}(B, C) =
\sum_{x \in B}
\sum_{y \in C}
\frac{
\operatorname{cosine\_distance}(x, y)
}
{
|B| \times |C|
}
.
\end{equation*}

\item
Repeat step 2 until only a single cluster containing all doculects is left.
\end{enumerate}

UPGMA was found to be preferable to other
distance matrix-based hierarchical clustering methods
for analyzing dialect distances by \citet[p. 153]{heeringa2004measuring},
and among several clustering methods suited for dialectometry
by \citet{prokic2008recognizing}.

Henceforth, we refer to the results of this approach
as \textit{UPGMA-context} and \textit{UPGMA-nocontext}.

\subsubsection{Bipartite Spectral Graph Co-clustering}
\label{subsubsec:bsgc}

For the other clustering method, we use the approach
introduced by \citet{dhillon2001co-clustering}.
We follow \citeauthor*{wieling2009bipartite} who introduced
this method to dialectometry for flat clustering (\citeyear{wieling2009bipartite}; \citeyear{wieling2011bipartite}) and hierarchical clustering \citeyearpar{wieling2010hierarchical}.

For this approach, we use a binary version of the
doculect-by-correspondence tally matrix that only
indicates whether a doculect exhibits
a sound correspondence ($1$) or not ($0$).

This method works as follows:

\begin{enumerate}
\item 
We begin with normalizing the binary co-occurrence matrix
$A \in \R^{m \times n}$ ($m$~=~number of doculects, $n$~=~number of sound correspondences).
First, we create two diagonal matrices
$D_1  \in \R^{m \times m}$ and $D_2 \in \R^{n \times n}$ that, respectively,
contain the row sums and column sums of $A$.
We use these diagonal matrices to reduce
the importance of doculects (or correspondences)
that co-occur with a large number
of sound correspondences (or doculects).
Accordingly, we create the normalized matrix $A_n$
by dividing each entry in $A$ by
the square root of the sum of its row's entries
and by the square root of the sum of its column's entries:
\begin{equation*}
A_n = D_1^{-\frac{1}{2}} \times A \times D_2^{-\frac{1}{2}}.
\end{equation*}

\item
We perform singular value decomposition on $A_n$,
that is, we decompose $A_n$ into the product of three matrices such that
$A_n = U\Sigma{}V^T$
($U~\in~\R^{m \times m}$,
$\Sigma{}~\in~\R_{\geq 0}^{m \times n}$ being a 
diagonal matrix with values in descending order,
$V~\in~\R^{n \times n})$
to obtain the left and right singular vectors $u_i$ and $v_i$
(columns of $U$ and $V$, respectively).
We ignore the singular vectors belonging
to the largest singular value as they do not contain
information relevant for partitioning the data \citep{kluger2003spectral},
and work with the second singular vectors ($u_2$, $v_2$) instead.
We calculate the vector $Z \in \R^{(m + n) \times 1}$ such that
its first $m$ entries contain information about the doculects
and the following $n$ entries about the sound correspondences:
\begin{align*}
Z_{[0, m]} = D_1^{-\frac{1}{2}} \times u_2\\
Z_{[m, m+n]} = D_2^{-\frac{1}{2}} \times v_2
.
\end{align*}

\item
We perform k-means clustering on $Z$ with $k = 2$.%
\footnote{%
We use the k-means++ algorithm \citep{arthur2007kmeanspp} for semi-arbitrarily picking the initial cluster centres.}

\item
For each cluster that contains at least two doculects,
we create the binary co-occurrence matrix $A$ describing
the doculects and sound correspondences in this cluster,
and repeat all steps.
\end{enumerate}

If a cluster produced in step 3 contains
sound correspondences that are not exhibited
by any of the doculects in this cluster,
we assign this correspondence to the other cluster.
This only happens rarely, and in these cases the corresponding
value in $Z$ is near the k-means decision boundary.
We need to change the cluster identity in such situations,
as it would otherwise not be possible to normalize
the cluster's co-occurrence matrix when partitioning
the cluster elements again.

The results from this method are hereafter referred to
as \textit{UPGMA-context} and \textit{UPGMA-nocontext}.

\subsection{Ranking Sound Correspondences by Importance}
\label{subsec:ranking}

When all doculects have been assigned to this hierarchical cluster structure,
we rank the sound correspondences associated with each cluster.
In the case of the UPGMA method, these are
all sound correspondences exhibited by each cluster's doculects;
for the graph clustering method,
these are the sound correspondences that are in the same cluster.

We use the representativeness and distinctiveness metrics
introduced by \citet{wieling2011bipartite},
as well as a modified version of their importance measure.

Representativeness measures how many doculects in a given cluster
exhibit a given sound correspondence:

\begin{equation*}
\operatorname{rep}(cluster_i, corres_j) = 
\frac{\text{number of doculects in } cluster_i \text{ with }  corres_j}
{\text{number of doculects in }  cluster_i}
.
\end{equation*}

Representativeness is bounded between
$0$ (no doculects in the cluster show the given sound correspondence)
and $1$ (all doculects in the cluster do).

Distinctiveness indicates how often a given sound correspondence
occurs in a given cluster compared to other clusters. 
This requires two additional measures:
relative occurrence, which indicates
the proportion of doculects exhibiting
a given sound correspondence in a given cluster,
and relative size, which gives the number of doculects 
in the cluster relative to the number of all examined modern doculects:

\begin{adjustwidth}{-1cm}{-1cm}
\begin{align*}
\operatorname{relative\_occurrence}(cluster_i, corres_j) &= 
\frac{\text{number of doculects in } cluster_i \text{ with }  corres_j}
{\text{total number of doculects with } corres_j}\\
\operatorname{relative\_size}(cluster_i) &= 
\frac{\text{number of doculects in } cluster_i}
{\text{total number of doculects}}
.
\end{align*}
\end{adjustwidth}

These two concepts are combined to determine the distinctiveness score:

\begin{adjustwidth}{-1cm}{-1cm}
\begin{equation*}
\operatorname{dist}(cluster_i, corres_j) = 
\frac{\operatorname{relative\_occurrence}(cluster_i, corres_j) - \operatorname{relative\_size}(cluster_i)}
{1 - \operatorname{relative\_size}(cluster_i)}
.
\end{equation*}
\end{adjustwidth}

Distinctiveness has an upper bound of
$1$ (a given sound correspondence only occurs in a given cluster),
but no lower bound.
A value of $0$ means that the sound correspondence
has the same relative frequency within the cluster
as among the total set of doculects.
Negative values indicate that the sound correspondence
is (proportionally) rarer within the cluster
than among all doculects.

Importance is the average of representativeness and distinctiveness.
\citet{wieling2011bipartite} use the arithmetic mean
and mention the possibility of exploring
other ways of combining the two metrics.
We use the harmonic mean in order to penalize cases
where the representativeness value is very high
but the distinctiveness value is very low (or vice versa).
We also assign an importance score of $0$ to
cases with negative distinctiveness values:

\begin{adjustwidth}{-3cm}{-3cm}
\begin{equation*}
\operatorname{imp}(cluster_i, corres_j) = 
\begin{dcases}
\frac{
2 * \operatorname{rep}(cluster_i, corres_j) * \operatorname{dist}(cluster_i, corres_j)}
{\operatorname{rep}(cluster_i, corres_j) + \operatorname{dist}(cluster_i, corres_j)}, & \text{if dist}(cluster_i, corres_j) > 0\\
0, & \text{otherwise}.
\end{dcases}
\end{equation*}
\end{adjustwidth}

We additionally re-rank correspondences
with the same importance score
so that more frequent correspondences rank higher.

\section{Results}
\label{sec:results}

The sound correspondence extraction for our data
yields 201 correspondences without context information,
292 with simple context information,
111 with sound class-based context information,
and 62 with word boundary information.

Using these sound correspondences for
applying the aforementioned methods results in
four arrangements of the data into hierarchical partitions,
two for the UPGMA method and two for the graph clustering method.

\subsection{Agglomerative Clustering}

Figure~\ref{fig:tfidf-dendrograms} shows the dendrograms
created by the UPGMA method for sound correspondences
including and excluding contextual information.
Of the 18 intermediary clusters
(i.e. clusters that are neither singletons nor contain all doculects),
13 are associated with a sound correspondence with an importance score of at least 70\% for the context-less run,
and 17 for the run with additional contextual information.

\begin{figure}[h]
\begin{adjustwidth}{-1cm}{-1cm}
% Importing the dendrograms as PDFs instead of via standalone
% because the latter messes up the placement of the sound corres labels.
\includegraphics[height=0.45\textheight]{figures/tfidf-nocontext.pdf}\\
\includegraphics[height=0.45\textheight]{figures/tfidf-context.pdf}
\end{adjustwidth}
\vspace{0.3em}
\begin{center}
{\ingv} Ingv\ae{}onic \hspace{1em}
{\dutch} Dutch \hspace{1em}
{\central} Central German \hspace{1em}
{\upper} Upper German
\end{center}
\caption
[UPGMA with no and with additional context information]
{UPGMA with no (top) and additional (bottom) context information,
as well as the highest-ranking correspondence per non-singleton cluster
(with $\geq$70\% importance).}
\label{fig:tfidf-dendrograms}
\end{figure}

The cosine similarity table which is
the basis for the UPGMA-context dendrogram
is described in section~\ref{subsubsec:cosine}.

In total, 201 sound correspondence were used for the run without contextual information,
of which 6 have importance scores of 100\% for intermediary clusters.
For the run with contextual information,
24 sound correspondences (of 665 total) reach 100\% importance for intermediary clusters.
Tables~\ref{tab:tfidf-nocontext-corres} and \ref{tab:tfidf-context-corres}
show the highest-ranking sound correspondences (importance score $\geq$ 90\%)
for UPGMA-nocontext and UPGMA-context, respectively.

\begin{table}[h]
\begin{adjustwidth}{-1cm}{-1cm}
\centering
\input{tables/tfidf-nocontext-corres}
\end{adjustwidth}
\caption
[Sound correspondences with an importance score of 90\% or higher for UPGMA-nocontext]
{Sound correspondences with an importance score of 90\% or higher for UPGMA-nocontext.
Importance, representativeness, and distinctiveness scores are percentages
and rounded to the nearest integer.
}
\label{tab:tfidf-nocontext-corres}
\end{table}

\begin{table}[h]
\begin{adjustwidth}{-1cm}{-1cm}
\centering
\input{tables/tfidf-context-corres}
\end{adjustwidth}
\caption
[Sound correspondences with an importance score of 90\% or higher for UPGMA-context]
{Sound correspondences with an importance score of 90\% or higher for UPGMA-context.
Importance, representativeness, and distinctiveness scores are percentages
and rounded to the nearest integer.
}
\label{tab:tfidf-context-corres}
\end{table}
\FloatBarrier

\subsection{Bipartite Spectral Graph Clustering}

The results for the graph clustering method are
displayed in Figure~\ref{fig:bsgc-trees}.
Again, the doculects are sorted into 18 intermediary clusters.
Of these, 6 contain at least one sound correspondence
with an importance rating of 70\% or above for the context-less run,
and 10 for the run with additional context information.

Of the 201 sound correspondences for BSGC-nocontext,
1 has an importance score of 100\% for an intermediary cluster
(the only sound correspondence with an importance value $\geq$ 90\%).
For the intermediary clusters of BSGC-context, 2 out of 665 correspondences reach
an importance score of 100\% and
a total of 9 sound correspondences
reach at least 90\%.
Table~\ref{tab:bsgc-corres} presents these high-ranking
sound correspondences for both BSGC runs.

It should be noted that the results concerning smaller subclusters are
(due to the random k-means initialization) not stable
across runs, although the overall results have stayed similar.

\begin{table}[h]
\begin{adjustwidth}{-1cm}{-1cm}
\centering
\input{tables/bsgc-nocontext-corres}\\
\vspace{1.5em}
\input{tables/bsgc-context-corres}
\end{adjustwidth}
\caption
[Sound correspondences with an importance score
of 90\% or higher for BSGC-nocontext and BSGC-context]
{Sound correspondences with an importance score
of 90\% or higher for BSGC-nocontext (top) and BSGC-context (bottom).
Importance, representativeness, and distinctiveness scores are percentages
and rounded to the nearest integer.
}
\label{tab:bsgc-corres}
\end{table}

\begin{figure}[h]
\begin{adjustwidth}{-1.5cm}{-1cm}
\centering
\includestandalone[height=0.42\textheight]{figures/bsgc-nocontext}\\
\vspace{1.5em}
\includestandalone[height=0.45\textheight]{figures/bsgc-context}
\end{adjustwidth}

\vspace{0.5em}
\begin{center}
{\ingv} Ingv\ae{}onic \hspace{1em}
{\dutch} Dutch \hspace{1em}
{\central} Central German \hspace{1em}
{\upper} Upper German
\end{center}
\caption
[BSGC with no and with additional context information]
{BSGC with no (top) and additional (bottom) context information,
as well as the highest-ranking correspondence per non-singleton cluster
(with $\geq$70\% importance).}
\label{fig:bsgc-trees}
\end{figure}

\subsection{Comparisons to Continental West Germanic Groupings}

For all methods, the first (in the figures: rightmost) split
creates one group containing only Dutch, Low German and Frisian doculects,
and one group containing a mixture of 
a few doculects belonging to the aforementioned categories as well as
mostly Central or Upper German doculects.
We refer to the former group as the Northern cluster and to the
latter as the Southern cluster.

\FloatBarrier
% \subsubsection{Comparison with Glottolog tree}
% comparison with language ancestry data from \citet{hammarstroem2018glottolog}

\subsubsection{North Sea Germanic}

For all approaches, the Ingv\ae{}onic doculects
are distributed across several not directly connected clusters.
These are, by method, (from least to most connected):

\begin{itemize}
\item
BSGC-nocontext:
None of the Ingv\ae{}onic doculects share a cluster
with only other Ingv\ae{}onic doculects.
% Three of them

\item
BSCG-context:
Westerkwartier and Heligoland are clustered together.

\item
TFIDF-nocontext:
Achterhoek and Veenkoloni\"{e}n form a cluster,
as do Heligoland and Westerkwartier.

\item
TFIDF-context:
Achterhoek and Veenkoloni\"{e}n also form a cluster.
Feer, Heligoland and Westerkwartier form another cluster.
\end{itemize}

All results include several Ingv\ae{}onic doculects
in the Southern cluster (this is expanded upon in the following subsection).
In all cases, these
samples include both doculects categorized as \textit{Northern Frisian}
in Glottolog \citep{hammarstroem2018glottolog}: Feer and Heligoland.

The phonological characteristics of Ingv\ae{}onic doculects
as detailed by \citet{stiles2013pan-west}
(changes to /*\textscripta{}/, palatalization of /*k/ and /*g/)
are not reflected in any of the results.

\subsubsection{Results of the High German Sound Shift}

For both BSGC runs, the results can be compared to the consonant shift-based grouping as follows:
The majority of the Low German/Dutch/Frisian doculects are in
the Northern cluster,
although four of them are distributed throughout the Southern cluster.
(In BSGC-nocontext,
the samples in the latter group are not directly clustered together,
but in BSGC-context,
two of them are (Westerkwartier and Heligoland).)
The Central German doculects from Cologne and Luxembourg
are not directly clustered together; the smallest cluster they share
is with four other doculects.
Of the Upper German doculects,
Walser and Biel are directly clustered together,
as are T\"{u}bingen and Ortisei.
The other three Upper German samples are distributed throughout
the Southern cluster.

By contrast, the results of the UPGMA runs fit
the grouping based on the High German sound shift more closely.
Again, most of the samples from the Low German/Dutch/Frisian group
constitute the Northern cluster.
The remaining samples from this class are clustered together
to different degrees in the different runs:
In UPGMA-nocontext,
Heligoland and Westerkwartier are directly grouped together,
but the remaining two doculects (Feer and Limburg) are not.
In UPGMA-context on the other hand,
there are only three doculects outside the Northern cluster
(Heligoland, Feer, Westerkwartier),
and they are all grouped together.

Both Central German doculects are directly clustered together
for both UPGMA runs. In addition, for both runs, one of the
Upper German doculects (T\"{u}bingen) is grouped with the
Central German samples; the rest form their own cluster.

The outcomes of the High German sound shift or lack thereof
are also visible in some of the highest-ranked sound correspondences.

In case of the UPGMA-context run,
the sound correspondence rules with 100\% importance scores
for (subclusters within) the Northern cluster
all reflect some of the unvoiced stops not being weakened:
/*k/~$>$~[k]~/~\#\_, /*t/~$>$~[t]~/~\_\#, /*k/~$>$~[k]~/~\_\textit{vow}.

Conversely, the predominantly Upper German clusters
have high-ranked\linebreak correspondences demonstrating lenition:
/*t/~$>$~[\texttoptiebar{ts}], /*t/~$>$~[\texttoptiebar{ts}]~/~\#\_,\linebreak
/*t/~$>$~[\texttoptiebar{ts}]~/~\_\textit{vow} (UPGMA-context)
and /*t/~$>$~[s] (UPGMA-nocontext, BSGC).
None of the sound correspondences with high importance values
describe the affrication or spirantization of /*k/ or /*p/
for any of the clustering approaches,
although it has to be noted that with the given data,
none of the sound correspondences based on /*p/
occurred often enough to actually be used for clustering.

Nevertheless, the sound correspondence /*k/~$>$~[k\textsuperscript{h}]
(on its own or prevocally) also has high importance scores
for the Southern group.
However, this still matches the assertion that /*k/
was the most resistant to change during the High German sound shift.

\subsubsection{Close Doculects Outside these Groupings}
\label{subsubsec:cosine}

In this section, we consider the results from
the UPGMA-context run more closely,
since it is the method whose results match the
groupings in the literature the most.
The cosine similarity matrix that is the basis for the
hierarchical clustering step is visualized in Figure~\ref{fig:cosine}.

The pairwise cosine similarity values showcased in this figure
show geographically close as well as geographically distant connections
with high similarity scores,
some of which are less apparent after the hierarchical clustering step.

Proceeding from (North) West to (South) East on the map,
we get the following connections:

Among the doculects spoken in Belgium and the Netherlands,
there is a tight cluster of Belgian doculects (Ostend, Antwerp, Std. Dutch (BE))
which are connected to the Veenkoloni\"{e}n doculect via Ostend,
which is in turn very similar to that spoken in Achterhoek.

The doculect spoken in Westerkwartier is very dissimilar to
the doculects which are its direct neighbours (Grou and Veenkoloni\"{e}n),
but it forms a tight cluster with Heligoland and Feer.

Heligoland and Feer are also very similar to the Luxembourg doculect.
Luxembourg, Feer and T\"{u}bingen are directly connected,
as are Luxembourg, T\"{u}bingen and Cologne.
However, there are low cosine similarity scores between
the latter three doculects and
the doculects from Limburg and Herrlisheim,
both of which are geographically close to this group.

T\"{u}bingen, Graub\"{u}nden and Walser form another
triangle cluster with high pairwise cosine similarity scores.
Walser is also very similar to the Hard doculect,
which is only moderately similar to the samples
from T\"{u}bingen and Graub\"{u}nden.

Lastly, the doculects spoken in Herrlisheim and Ortisei
show high cosine similarity to one another but not to their
geographic neighbours.

\begin{figure}[h]
\begin{adjustwidth}{-3cm}{-3cm}
\centering
\includestandalone[width=0.75\textwidth]{figures/cosine}
\hspace{-7em}
\includestandalone[width=0.75\textwidth]{figures/cosine2}
\end{adjustwidth}
\caption
[Cosine similarities between the doculects (UPGMA-context)]
{
Cosine similarities between the doculects (UPGMA-context).
Lines that are bolder and darker represent greater cosine similarity scores
(i.e. lower cosine distances).
The graphic on the left includes all pairwise similarity scores;
the one on the right only includes the highest 10\% of cosine similarity scores.
}
\label{fig:cosine}
\end{figure}


\subsection{Context Information}

As shown in the preceding subsections,
the runs with context information yield results
that are overall closer to the proposed groupings
than the runs without additional information.

Moreover, for the runs with additional context information,
higher proportions of the clusters are associated with
sound correspondences (of $\geq$ 70\% importance):
6/18 versus 10/18 for the graph clustering approach
(without and with context information, respectively),
and 13/18 versus 17/18 for UPGMA-nocontext and UPGMA-context.

Most of the high-ranking sound correspondences
use the vowel/consonant distinction instead of
the more detailed sound classes.
Additionally, word boundary-based correspondences are also very common
among the high-ranking sound correspondences.

% \newpage
\section{Discussion}
\label{sec:discussion}

\subsection{Clusters}
The clusters formed by the different approaches
match the groupings from the literature to different degrees.
The UPGMA runs show these patterns more strongly than the BSGC runs,
and UPGMA-context follows it the most closely.

However, even in UPGMA-context,
we see some unexpected results,
such as several Frisian/Low German doculects
being clustered with a group of Central/Upper German doculects
instead of the large Frisian/Low German/Dutch group.

Overall, we can also observe that the results reflect
the High German sound shift-based groupings more
strongly than the (Non-)Ingv\ae{}onic distinction,
unless we (re-)define Ingv\ae{}onic to include Dutch as well,
as \citet{sonderegger1979grundzuege} does.

Inspecting the cosine similarity values
for UPGMA-context, we can observe a pattern
that shows both some isolated subgroups and
a more net-like pattern of connections
reflecting more gradual changes.
These latter pattern matches the observations
by \citet{heggarty2010splits} for the same dataset.
It would be interesting to investigate these gradual changes further,
for instance following the fuzzy dialect clustering approaches
by \citet{proell2013detecting}, which are better suited to model
wave-like developments of language variation.

A promising approach would be to run
clustering methods (fuzzy or not) on a larger amount of data.
This should be both in terms of the number of doculects
to gain a more representative depiction of the CWG doculect landscape
(adding places that are geographically located
in between some of the doculects we worked with,
and adding doculects from CWG-speaking places that
were not at all included in this analysis,
such as more locations in Germany)%
\footnote{%
Adding more doculects spoken near the Dutch border
would make it possible to investigate the tendency for
standard language borders to act as dialect borders.
In addition, incorporating data from central or eastern
Germany would noticeably increase the diversity of CWG doculects
covered in such an investigation.
}
and in terms of concepts per doculect
(to capture a greater variety of sound correspondences).
Unfortunately, we are not aware of
a digital database compiled by a single transcriber that
would allow us to do that.

\subsection{Bipartite Spectral Graph Co-clustering}

As mentioned before, the co-clustering approach
does not match the groupings described in the literature very well
compared to the simpler UPGMA approach.

In our experiments, one issue with BSGC is that some
sound correspondences get assigned to the wrong clusters
in that they do not actually co-occur with any of the
doculects in their assigned clusters.
In such cases, we automatically assign them to the appropriate
other cluster to avoid linear algebra problems.
However, it is possible that such an unfitting
cluster assignment also happens with other samples
% that are close to the k-means decision boundary,
% ending up in a cluster where they describe the doculects
% not as well as they would have in the other cluster.
that get sorted into the cluster whose
doculects they not describe as well as the other cluster's.

In the future, it would be interesting to
explore if alternate approaches to normalizing the data
would mitigate this problem.

However, BSGC yielded good results for \citeauthor{wieling2011bipartite}
(\citeyear{wieling2009bipartite}; \citeyear{wieling2010hierarchical}; \citeyear{wieling2011bipartite}),
\citet{wieling2013analyzing} and \citet{montemagni2013synchronic}.
There are several differences between their data and ours.
First, all of these experiments used a larger number
of doculects and concepts.
Additionally, the doculects they used are
generally from smaller geographic areas.
Moreover, all of them used modern reference dialects.
The transcriptions they worked with might also have been broader,
potentially allowing for sound correspondences that are similar in our data,
but (due to the narrowness of transcription) slightly different,
to become identical and thus more common.

Another follow-up investigation would be to investigate the influence of
data selection and preprocessing on BSGC performance.

\subsection{Sound Correspondences}

Adding context information to the sound correspondences
helps the UPGMA model to match the groupings in the literature more closely.
However, most of the high-ranking sound correspondences
do not involve the more detailed sound class model.
It is possible that these sound classes are too specific
for the data at hand or have the wrong kind of specificity,
being thus not well-suited for capturing generalizations of the data.

A solution to this would be using a more simple context system.
Additionally, it would also be possible to 
use more sound segment and context representations with
varying degrees of superficiality or abstractness 
to model sound changes as specifically or generally as appropriate
for each resulting cluster.

The current system cannot pick up on related changes
with slightly different outcomes, such as different
ways that Proto-Germanic /*k/ has developed into
an affricate or fricative in Swiss German doculects:
/*k/~$>$~[\texttoptiebar{kx}], /*k/~$>$~[x], /*k/~$>$~[\textchi].
Again, a way of describing these sound changes more abstractly
might make it possible to consider the similarity of
these sound changes while clustering doculects.

In future experiments, it might be worthwhile to rank
sound correspondences also by how regular they are,
i.e. how often a given sound shifted into a specific sound
compared to how often another sound shift (or no sound shift) took place instead.
This could be done in a similar fashion to the approaches by
\citet{prokic2007identifying} and \citet{prokic2013combining}.

In this thesis, all of the comparisons between Proto-Germanic
and modern CWG doculects are phonological
% (and might possibly include some morphological information in some cases)
and on a word level.
Investigating the effect of additionally incorporating
morphological, lexical and syntactical information
would be interesting for further research.

\section{Conclusion}
\label{sec:conclusion}

In this thesis, we have implemented two methods
for clustering doculects on the basis of shared
historical sound correspondences,
and compared the results to common (although not uncontroversial)
groupings of the doculects we worked with.

We showed that, compared to the graph co-clustering method (BSGC),
the agglomerative clustering approach (UPGMA)
yielded results that are more similar to the groupings in the literature
and are associated more frequently sound correspondences that
describe the subclusters well.

Additionally, we examined the effect of adding information about
the phonetic context in which specific sound shifts take place,
and showed that adding such information also resulted in
clusters that match the literature more closely and that
can more frequently be described with relevant sound correspondences.

Further investigation is needed for exploring the
differences in the results between the two clustering approaches.
Moreover, we hope to examine how the representation of
sound shifts can be improved to describe them in
as much detail or abstraction as required for good clustering results.
In addition, it would be worthwhile to pursue ways
of combining these approaches with fuzzy clustering techniques
to better capture transitions within dialect continua.

% \newpage
\bibliographystyle{chicago}
\bibliography{lib}
\end{document}
